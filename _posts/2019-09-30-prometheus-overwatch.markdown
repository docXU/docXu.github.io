---
layout:     post
title:      "监控系统 - 思路与选型"
subtitle:   "overwatch the world, then handle it."
date:       2019-09-30 18:59:00
author:     "MattX"
header-img: "img/post-bg-js-module.jpg"
tags:
    - 监控
    - prometheus
    - 时序数据库
---

> 监控 + 预测 + 告警

想象一个场景，我们需要这么一个模块:针对业务数据实现准实时监控和数据分析，将期望观察的数据分析结果通过可视化方式提供给决策人员，并提供辅助告警机制。
这些指标包括但不限于(某段时间系统中接口通过率，某种业务参数变化后系统响应差异，接口请求耗时分布，硬件节点健康状态... )
 
那么,如何实现这个需求呢? （我的设想，箭头表明数据流）

```

     业务系统生成监控指标 → 监控系统收集时序数据并存储 → 查询分析语言 → 可视化图表
                                    ↓
                             发送监控规则告警 

```

> Let‘s begin。选择一个适合我们的监控方案。

***不要自己造轮子，特别是立刻需要你跑F1车道的时候***

是否有什么框架可以帮助我们实现这个方案？

首先得确认一个概念：监控中心应该是作为一个独立的服务运行(归属于中间件)，它不应该与任何业务系统耦合。监控中心通过或主动或被动的方式从业务系统获取监控指标（通过收集器），经过归纳后持久化于某种数据库，在可视化时再通过一类查询语句(Math)实时地从数据源分析并展示数据。


1. 如何生成数据
    * 收集器行为对比（对指标的收集有以下几类）
    
    | 使用方式 | 评价 | 相关工具 |
    | :--- | :------------- | :--- |
    |日志解析|开发人员遵循规范的日志格式，在业务代码中打印关键信息到日志文件里，运维研发配置脚本定时从这些文件中解析数据(通过一个系统级服务程序,将解析得到的数据推给监控中心)。	公司目前使用的方式，这使得添加监控指标时需要开发运维一起协作，开发梳理指标并打印状态值，运维出脚本解析数据配置监控项。这在监控项比较简单时是最好的选择。但在监控指标灵活变化的场景下就不合适了。|Zabbix-agent logstash flume|
    |内存保留|开发人员将需要监控的数据值通过四种基本指标元素（counter，guage，summary，histogram 详情了解）保留在内存中，在某个时刻，监控系统会定时收集这些数据。	运维和开发之间的协作就可以并行了，开发人员自定义指标并暴露给监控系统，监控系统拉取所有的指标，再也无需运维编写脚本了。数据分析人员直接通过分析语言从监控系统自主地获取指标，这是理所应当的方式，对于一个监控目标，及时的获取与修改应该使用面向对象的思维，这更可控且增加了代码阅读性。|Prometheus telegraf StatsD|
    
    需要注意的是： 监控中心获取应用系统提供的数据的行为分为两种(主动拉取和被动接受)，主动拉取的方式就是由监控中心定时向应用实例收集数据；而被动接受指的是应用实例端定时的推送数据给监控中心。当两种方式结合数据运算时就要考虑选择哪种方式对系统的整体可靠性影响较小。

2. 数据的持久化

    收集完数据后，用户便可以对这些数据进行查询分析，但不可避免的是数据量大的时候内存不足以表达，就得存放在数据库了。对于监控的数据来说，其天生自带时间属性，这种前提下采用以时间戳为主键的时序数据库是最佳的方案。
    
    * 数据库对比
    
    | | 优势 | 评价 |
    | :--- | :------------- | :--- |
    | 关系性数据库 |最熟悉的数据库，可以通过自定义时间主键实现时序数据库特性。 | 不解释 |
    | influxDB | 专业的时序数据库，基于时序数据进行优化，不仅读写性能好，还体现在删除性能和稳定性方面	| 但是是独立的一个组件，用于监控系统的话需要再结合数据搜集器，告警模块，这在运维方面增加负担| 
    | Prometheus 内建数据库 | 同上 | Prometheus 提供的是一整套监控体系，包括数据采集SDK，数据存储，报警，甚至是绘图(只不过很烂,官方也推荐使用 grafana). 还提供了数据统计API|

3. 查询统计与分析

    * 读到这，应该能看出我想种草的监控中心是Prometheus，这是一个目前为止最适合我们学习使用的监控方案了。
    * 在这个环节，才是Prometheus最拿手的部分。当然我们还是要对比一下其它方案
    * 例如在可视化时，想绘制一个【1分钟内CPU使用率】曲线图 ，对比一下查询语言：
    
    | |例子|评价|
    | :--- | :------------- | :--- |
    |InfluxData 的 InfluxQL	| `SELECT 100 - usage_idel FROM "autogen"."cpu" WHERE time > now() - 1m and "cpu"='cpu0'`|类似SQL 的查询语句,支持统计函数,但可见一个简单的查询需要编写复杂的查询语句,似乎更显麻烦和啰嗦|
    |Prometheus 的 PromQL| `100 - (node_cpu{job="node",mode="idle"}[1m])` | 看起来像是JSON的设计，同样支持统计函数，即使是复杂的查询，语句也不会太长，而且可读性极佳，不愧是谷歌出品。|

4. 告警
    * 告警是监控系统最实用的地方，总结历史数据目前的瓶颈，通过设置合理的规则（阈值），及时告知用户关键信息。
    * 简单的告警可以通过可视化组件实现（如Grafana），这些组件在查询数据时集成了Alert功能，简单设置即可实现告警。
    * 基本的需求是，我们需要实现自定义告警通知，将关键告警通过各种方式发送，包括邮箱，微信，MQ，Webhook。。。这时就需要一款优秀的框架协助了，在这方面InfluxData的Kapacitor组件提供了支持， Prometheus的AlertManager也是这个目的，他们都提供了更丰富的告警信息管理功能：包括通知Group（分组），Inhibition（去重），Silences（静音）。 
    * 在使用体验上，AlertManager比Kapacitor更方便，而且他也是属于Prometheus生态系统的。
5. 集群和高可用
    * 当系统的监控量上来后，单台监控中心就成为了瓶颈，这时需要考虑是否监控系统是否有集群能力，很遗憾，Prom和Influx都没有免费的集群版本，Influx有商用集群版本（遗憾+1），Prom只可以通过部署多个实例实现，但这么做需要系统架构就复杂了，好在目前的v3版本在单点上表现非常可观，至少内存消耗和性能表现都很优秀。

That's All, Prometheus无论是作为玩具还是生产工具都非常值的我们研究，希望后续有精力可参与源码建设。

关于Prom的更多介绍和实战及原理讲解后续有空了再补充。
---
 

 

 